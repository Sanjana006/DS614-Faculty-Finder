# DS614 (Big Data Engineering) â€“ Faculty Finder Project

---

## ğŸ“Œ Project Overview

Faculty Finder is a data engineering project that automates the entire process of collecting, cleaning, storing, and serving faculty information from the DA-IICT website. Instead of manually browsing multiple pages, the system converts scattered and unstructured faculty details such as bio, research interests, and publications into a clean, structured, and searchable format.

The project implements a complete data pipeline that includes web scraping, data transformation, database storage, and API-based data access. The processed data is stored in a SQLite database and exposed through a FastAPI REST API in JSON format, making it easy to use for analytics, machine learning, or future semantic search applications. The focus of this project is on building a reliable, modular, and real-world data pipeline that reflects how data engineering systems are designed in practice.

---

## ğŸ¯ Problem Statement

Faculty information on university websites is often spread across multiple pages and presented in inconsistent formats, which makes it difficult to search, analyze, or reuse the data effectively. Basic keyword searches are limited and do not capture the actual research expertise or interests of faculty members.

The goal of this project is to build a system that can automatically extract faculty data, clean and standardize it, and store it in a structured form that supports efficient querying and future intelligent search. The system is designed to handle common real-world challenges such as missing information, noisy text, and inconsistent web structures, while providing easy access to the data through a RESTful API for researchers and data-driven applications.

---

## ğŸ› ï¸ Tech Stack

Programming Language  
- Python â€“ Core language for pipeline, transformation, and API

Data Ingestion  
- Scrapy â€“ Web scraping and crawling faculty profile pages

Data Transformation  
- Pandas â€“ Data cleaning and normalization  
- Regular Expressions (re) â€“ Text cleaning and validation

Data Storage  
- SQLite3 â€“ Lightweight relational database

API & Serving  
- FastAPI â€“ REST API framework  
- Uvicorn â€“ ASGI server

Utilities  
- Python Logging â€“ Execution and error tracking  
- OS / Pathlib â€“ Path and file handling

---

## ğŸ—‚ï¸ Project Structure

DS614-Faculty-Finder  
â”‚  
â”œâ”€â”€ api  
â”‚   â”œâ”€â”€ main.py  
â”‚   â””â”€â”€ routes.py  
â”‚  
â”œâ”€â”€ config  
â”‚   â””â”€â”€ settings.py  
â”‚  
â”œâ”€â”€ data  
â”‚   â”œâ”€â”€ raw  
â”‚   â”‚   â””â”€â”€ Faculty_DAIICT.csv  
â”‚   â”œâ”€â”€ cleaned  
â”‚   â”‚   â””â”€â”€ transformed_faculty_data.csv  
â”‚   â””â”€â”€ database  
â”‚       â””â”€â”€ faculty.db  
â”‚  
â”œâ”€â”€ ingestion  
â”‚   â””â”€â”€ daiict_faculty  
â”‚       â””â”€â”€ spiders  
â”‚           â””â”€â”€ daufaculty.py  
â”‚  
â”œâ”€â”€ transformation  
â”‚   â”œâ”€â”€ normalize_text.py  
â”‚   â””â”€â”€ transform_pipeline.py  
â”‚  
â”œâ”€â”€ storage  
â”‚   â”œâ”€â”€ db_connection.py  
â”‚   â””â”€â”€ database_insertion.py  
â”‚  
â”œâ”€â”€ scripts  
â”‚   â””â”€â”€ __main__.py  
â”‚  
â”œâ”€â”€ logs  
â”‚   â”œâ”€â”€ pipeline.log  
â”‚   â”œâ”€â”€ scraper.log  
â”‚   â””â”€â”€ llm_usage.md  
â”‚  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ README.md  
â””â”€â”€ LICENSE  

---

## ğŸ”„ Data Pipeline Description

The project follows a modular pipeline where each stage prepares data for the next.

Ingestion  
- Scrapes faculty profiles from DA-IICT website  
- Extracts name, bio, research interests, specialization, publications  
- Output stored as raw CSV  
Output: data/raw/Faculty_DAIICT.csv  

Transformation  
- Cleans HTML and encoding noise  
- Normalizes text, emails, and names  
- Generates faculty IDs  
- Creates combined_text for NLP  
Output: data/cleaned/transformed_faculty_data.csv  

Storage  
- Inserts cleaned data into SQLite  
- Auto-creates tables if missing  
- Ensures transactional safety  
Database: data/database/faculty.db  

Serving (API)  
- Exposes data via FastAPI  
- Supports /faculty and /faculty/{faculty_id} endpoints  
- Returns JSON responses  

---

## ğŸ—„ï¸ Database Schema

Table: faculty  

- faculty_id (TEXT, Primary Key)  
- name (TEXT)  
- mail (TEXT)  
- phd_field (TEXT)  
- specialization (TEXT)  
- bio (TEXT)  
- research (TEXT)  
- publications (TEXT)  
- combined_text (TEXT)

The combined_text field merges bio, research, specialization, and PhD field for NLP and semantic search readiness.

---

## â–¶ï¸ How the Project Works (Execution Flow)

1. Clone the repository and install dependencies from requirements.txt  
2. Review configuration in config/settings.py  
3. Scraping logic runs from ingestion/daiict_faculty/spiders/daufaculty.py  
4. Transformation runs from transformation/transform_pipeline.py  
5. Database insertion runs using storage/database_insertion.py  
6. Final unified pipeline is executed via scripts/__main__.py  
7. Logs are generated in the logs directory  
8. API is started independently from api/main.py  
9. Access all data via /faculty and individual data via /faculty/DAU001  

---

## ğŸ›¡ï¸ Error Handling and Logging

The pipeline is designed to continue execution even when partial failures occur.

- Scraping errors are logged and skipped  
- Profiles missing mandatory fields are ignored  
- Invalid values are validated during transformation  
- Failed database rows are skipped without stopping insertion  
- Critical database errors trigger rollback  

Logs provide full transparency into pipeline execution.

---

## âš ï¸ Limitations

- Scraper depends on current DA-IICT website structure  
- SQLite is not suitable for large-scale or concurrent workloads  
- API lacks pagination, filtering, and authentication  

---

## ğŸš€ Future Enhancements

- Semantic search using vector embeddings  
- API pagination and filtering  
- Docker-based deployment  
- Migration to PostgreSQL  
- Scheduled automated pipeline runs  

---

## ğŸ‘¥ Team Members

Team Name: The Data Engineers  

Sanjana Nathani  
- Student ID: 202518002  
- Program: M.Sc. Data Science  
- Institution: Dhirubhai Ambani University, Gandhinagar  
- Role: Data Engineer  

Aksh Patel  
- Student ID: 202518046  
- Program: M.Sc. Data Science  
- Institution: Dhirubhai Ambani University, Gandhinagar  
- Role: Data Engineer  

---

## ğŸ“„ License

This project is developed for academic purposes as part of the DS614 (Big Data Engineering) course.
